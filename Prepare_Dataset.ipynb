{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Objetivo:\n",
        "\n",
        "O objetivo deste notebook é realizar o processamento inicial de um arquivo JSON contendo dados de produtos.\n",
        "\n",
        "O foco está em carregar os dados e montar a estrutura de prompt para nosso treinamento."
      ],
      "metadata": {
        "id": "0ZmbmTSGWTV3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ3e2DDA_a87",
        "outputId": "a9130b4e-945a-4d18-b4c4-dcb2a3b52362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#Conexão com o Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos processar nosso dataset para o modelo que o fine-tuning pede para conseguir ser treinado!"
      ],
      "metadata": {
        "id": "ZogpXdc-eC_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Lista que armazenará os produtos carregados do arquivo JSON\n",
        "produtos_list = []\n",
        "def process_trn_file(file_path, processed_data):\n",
        "    \"\"\"\n",
        "    Lê um arquivo JSON contendo descrições de produtos e formata o conteúdo em um formato específico.\n",
        "    - file_path: Caminho para o arquivo JSON contendo os produtos.\n",
        "    - processed_data: Lista onde serão armazenados os dados processados.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        print(file)\n",
        "        # Lendo cada linha do arquivo JSON\n",
        "        for line in file:\n",
        "          json_data = json.loads(line.strip())\n",
        "          produtos_list.append(json_data)\n",
        "\n",
        "        # Processando cada item do arquivo de produtos\n",
        "        for item in produtos_list:\n",
        "            content = item[\"content\"]\n",
        "            title = item[\"title\"]\n",
        "            # Formatando o texto conforme o modelo de entrada para o fine-tuning\n",
        "            # Colocando DESCRICÃO como input e TÍTULO como output, ou seja, o usuário vai descrever um produto e o modelo irá trazer o TÍTULO dele.\n",
        "            formatted_text = f\"Encontre o seguinte produto.\\n[|Descricão|] {content}[|eDescricão|]\\n\\n[|Titulo|]{title}[|eTitulo|]\"\n",
        "            processed_data.append({\"input\": formatted_text}) #Adiciona o conteúdo formatado na lista processed_data"
      ],
      "metadata": {
        "id": "JRUjdreL_e93"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Por que utilizamos esse processo?\n",
        "\n",
        "O fine-tuning de modelos de linguagem requer que os dados de treinamento estejam organizados de uma maneira específica, geralmente com uma estrutura de instrução + entrada + resposta.\n",
        "\n",
        "No nosso caso, estamos utilizando as descrições de produtos como entrada e os títulos como respostas esperadas."
      ],
      "metadata": {
        "id": "7K9R6y6odpK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar todos os dados processados\n",
        "processed_data = []\n",
        "\n",
        "# Passamos aqui o nosso dataset de treinamento com as descricões e títulos dos produtos, e nossa varíavel que vai armazenar o resultado tratado.\n",
        "process_trn_file(r'/content/drive/MyDrive/Pós Tech - IA PARA DEVS/Pós Tech/FASE3/trn.json', processed_data)\n",
        "\n",
        "# Salvar os dados processados em um arquivo JSON chamado \"new_trn.json\"\n",
        "output_filename = r'/content/drive/MyDrive/Pós Tech - IA PARA DEVS/Pós Tech/FASE3/new_trn.json'\n",
        "with open(output_filename, 'w', encoding='utf-8') as file:\n",
        "    json.dump(processed_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Todos os dados reformatados foram salvos em '{output_filename}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROFkghn7_hGT",
        "outputId": "ce0d6fe2-fce7-4b6a-ce5f-93efc1f93ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='/content/drive/MyDrive/Pós Tech - IA PARA DEVS/Pós Tech/FASE3/trn.json' mode='r' encoding='utf-8'>\n",
            "Todos os dados reformatados foram salvos em '/content/drive/MyDrive/Pós Tech - IA PARA DEVS/Pós Tech/FASE3/new_trn.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Nossos dados foram preparados com sucesso!\n",
        "\n",
        "Devemos agora passar para nosso outro notebook \"Fine Tuning com Dataset.ipynb\" onde faremos mais alguns pequenos ajustes e treinaremos nosso modelo com os dados do dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BwRgRHhTZJTR"
      }
    }
  ]
}